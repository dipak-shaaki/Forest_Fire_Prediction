{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e672d3-8c43-45db-a1e2-fc4b441a5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Function to calculate Vapor Pressure Deficit (VPD)\n",
    "def calculate_vpd(temperature_celsius, relative_humidity):\n",
    "    \"\"\"\n",
    "    Calculates Vapor Pressure Deficit (VPD) in kPa.\n",
    "    Source: https://www.fruit.wisc.edu/VPD-and-Relative-Humidity-Calculations/\n",
    "    \"\"\"\n",
    "    if temperature_celsius is None or relative_humidity is None:\n",
    "        return None\n",
    "\n",
    "    # Saturation Vapor Pressure (Es) in kPa\n",
    "    # Magnus-Tetens formula (valid for T > 0 deg C)\n",
    "    Es = 0.6108 * np.exp((17.27 * temperature_celsius) / (temperature_celsius + 237.3))\n",
    "\n",
    "    # Actual Vapor Pressure (Ea) in kPa\n",
    "    Ea = (relative_humidity / 100) * Es\n",
    "\n",
    "    # Vapor Pressure Deficit (VPD) in kPa\n",
    "    VPD = Es - Ea\n",
    "    return VPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfe3b8e-dba7-424b-b73e-8b7822c7398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled. 8 rows dropped.\n",
      "Test dataset saved as fire_test_dataset.csv\n",
      "Data cleaning and splitting complete.\n",
      "X_train_scaled shape: (793, 8)\n",
      "X_test_scaled shape: (199, 8)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Cleaning and Preparation\n",
    "import pandas as pd\n",
    "import numpy as np # Ensure numpy is imported for array([])\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('fire_dataset_enriched.csv')\n",
    "\n",
    "    # Handle missing values by dropping rows\n",
    "    initial_rows = df.shape[0]\n",
    "    df = df.dropna()\n",
    "    rows_after_dropna = df.shape[0]\n",
    "    print(f\"Missing values handled. {initial_rows - rows_after_dropna} rows dropped.\")\n",
    "\n",
    "    # Drop non-numeric or non-useful columns for model training\n",
    "    # Check if 'acq_date' exists before dropping to prevent KeyError\n",
    "    if 'acq_date' in df.columns:\n",
    "        df = df.drop(columns=['acq_date'])\n",
    "    else:\n",
    "        print(\"Warning: 'acq_date' column not found, skipping drop.\")\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    # ENSURE X AND Y ARE NUMPY ARRAYS HERE BY ADDING .values\n",
    "    X = df.drop(columns=['fire_occurred']).values # X is now a NumPy array\n",
    "    y = df['fire_occurred'].values              # y is now a NumPy array\n",
    "\n",
    "    # Train-Test Split (80-20) - train_test_split handles NumPy arrays well\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Scale the features - StandardScaler takes NumPy arrays\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train) # Returns NumPy array\n",
    "    X_test_scaled = scaler.transform(X_test)     # Returns NumPy array\n",
    "\n",
    "    # Save the scaler for future use in manual predictions\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "    # Save test set - Ensure this block is present\n",
    "    # For saving, we need X_test as a DataFrame, so we recreate it temporarily if needed\n",
    "    # Or, if you want to save the original unscaled test data\n",
    "    # Let's use the unscaled X_test (which is a NumPy array from the split) and convert it back for saving\n",
    "    test_df_to_save = pd.DataFrame(X_test, columns=df.drop(columns=['fire_occurred']).columns) # Recreate DataFrame for saving\n",
    "    test_df_to_save[\"fire_occurred\"] = y_test\n",
    "    test_df_to_save.to_csv(\"fire_test_dataset.csv\", index=False)\n",
    "    print(\"Test dataset saved as fire_test_dataset.csv\")\n",
    "\n",
    "    print(\"Data cleaning and splitting complete.\")\n",
    "    print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "    print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'fire_dataset_enriched.csv' not found. Please run previous cells to generate it.\")\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data cleaning and preparation: {e}\")\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = np.array([]), np.array([]), np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf68255-8f76-407b-ba40-8d69bbace888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_rf import RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf08a06-3584-4217-9ad8-a56f55f67e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Training complete.\n",
      "\n",
      "Accuracy of Random Forest (from scratch): 0.8894\n",
      "\n",
      "Confusion Matrix:\n",
      "[[84 16]\n",
      " [ 6 93]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       100\n",
      "           1       0.85      0.94      0.89        99\n",
      "\n",
      "    accuracy                           0.89       199\n",
      "   macro avg       0.89      0.89      0.89       199\n",
      "weighted avg       0.89      0.89      0.89       199\n",
      "\n",
      "Random Forest model saved as 'random_forest_final_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model Training and Evaluation\n",
    "import joblib \n",
    "\n",
    "if X_train_scaled.size > 0:\n",
    "    # Train the Random Forest model\n",
    "    # You can adjust n_trees, max_depth, min_samples\n",
    "    forest = RandomForest(n_trees=100, max_depth=10, min_samples=5) # Increased n_trees for better performance\n",
    "    print(\"Training Random Forest model...\")\n",
    "    forest.fit(X_train_scaled, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    predictions = forest.predict(X_test_scaled)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nAccuracy of Random Forest (from scratch): {accuracy:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_test, predictions)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Save the trained model\n",
    "    joblib.dump(forest, 'random_forest_final_model.pkl')\n",
    "    print(\"Random Forest model saved as 'random_forest_final_model.pkl'\")\n",
    "else:\n",
    "    print(\"Skipping model training and evaluation: Training data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b0c881f-de8b-451d-8bf1-0484a7dc5d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'custom_rf.RandomForest'>\n",
      "custom_rf\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load('random_forest_final_model.pkl')\n",
    "print(type(model))\n",
    "print(model.__class__.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bf70d-5d68-413d-ab01-b74f8265769f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
