{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e49df6-5be3-4686-90ca-c8749ab9647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0dd9de1-7e85-4c30-9796-87f02e2f6f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6116334-1615-4ad2-9fc5-4471dd79774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Function to calculate Vapor Pressure Deficit (VPD)\n",
    "def calculate_vpd(temperature_celsius, relative_humidity):\n",
    "    \"\"\"\n",
    "    Calculates Vapor Pressure Deficit (VPD) in kPa.\n",
    "    Source: https://www.fruit.wisc.edu/VPD-and-Relative-Humidity-Calculations/\n",
    "    \"\"\"\n",
    "    if temperature_celsius is None or relative_humidity is None:\n",
    "        return None\n",
    "\n",
    "    # Saturation Vapor Pressure (Es) in kPa\n",
    "    # Magnus-Tetens formula (valid for T > 0 deg C)\n",
    "    Es = 0.6108 * np.exp((17.27 * temperature_celsius) / (temperature_celsius + 237.3))\n",
    "\n",
    "    # Actual Vapor Pressure (Ea) in kPa\n",
    "    Ea = (relative_humidity / 100) * Es\n",
    "\n",
    "    # Vapor Pressure Deficit (VPD) in kPa\n",
    "    VPD = Es - Ea\n",
    "    return VPD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e800405-f23a-41c6-a1ba-db22c197bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled. 8 rows dropped.\n",
      "Test dataset saved as fire_test_dataset.csv\n",
      "Data cleaning and splitting complete.\n",
      "X_train_scaled shape: (793, 8)\n",
      "X_test_scaled shape: (199, 8)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Data Cleaning and Preparation\n",
    "import pandas as pd\n",
    "import numpy as np # Ensure numpy is imported for array([])\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('fire_dataset_enriched.csv')\n",
    "\n",
    "    # Handle missing values by dropping rows\n",
    "    initial_rows = df.shape[0]\n",
    "    df = df.dropna()\n",
    "    rows_after_dropna = df.shape[0]\n",
    "    print(f\"Missing values handled. {initial_rows - rows_after_dropna} rows dropped.\")\n",
    "\n",
    "    # Drop non-numeric or non-useful columns for model training\n",
    "    # Check if 'acq_date' exists before dropping to prevent KeyError\n",
    "    if 'acq_date' in df.columns:\n",
    "        df = df.drop(columns=['acq_date'])\n",
    "    else:\n",
    "        print(\"Warning: 'acq_date' column not found, skipping drop.\")\n",
    "\n",
    "    # Define features (X) and target (y)\n",
    "    # ENSURE X AND Y ARE NUMPY ARRAYS HERE BY ADDING .values\n",
    "    X = df.drop(columns=['fire_occurred']).values # X is now a NumPy array\n",
    "    y = df['fire_occurred'].values              # y is now a NumPy array\n",
    "\n",
    "    # Train-Test Split (80-20) - train_test_split handles NumPy arrays well\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Scale the features - StandardScaler takes NumPy arrays\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train) # Returns NumPy array\n",
    "    X_test_scaled = scaler.transform(X_test)     # Returns NumPy array\n",
    "\n",
    "    # Save the scaler for future use in manual predictions\n",
    "    joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "    # Save test set - Ensure this block is present\n",
    "    # For saving, we need X_test as a DataFrame, so we recreate it temporarily if needed\n",
    "    # Or, if you want to save the original unscaled test data\n",
    "    # Let's use the unscaled X_test (which is a NumPy array from the split) and convert it back for saving\n",
    "    test_df_to_save = pd.DataFrame(X_test, columns=df.drop(columns=['fire_occurred']).columns) # Recreate DataFrame for saving\n",
    "    test_df_to_save[\"fire_occurred\"] = y_test\n",
    "    test_df_to_save.to_csv(\"fire_test_dataset.csv\", index=False)\n",
    "    print(\"Test dataset saved as fire_test_dataset.csv\")\n",
    "\n",
    "    print(\"Data cleaning and splitting complete.\")\n",
    "    print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "    print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'fire_dataset_enriched.csv' not found. Please run previous cells to generate it.\")\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = np.array([]), np.array([]), np.array([]), np.array([])\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data cleaning and preparation: {e}\")\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = np.array([]), np.array([]), np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "673ee64b-58b0-48c7-beab-adeebd88b6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest implementation loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Random Forest from Scratch Implementation\n",
    "# Gini Impurity Function\n",
    "def gini(y):\n",
    "    counts = Counter(y)\n",
    "    impurity = 1 - sum((c / len(y))**2 for c in counts.values())\n",
    "    return impurity\n",
    "\n",
    "# Dataset Split\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    left_indices = [i for i in range(len(X)) if X[i][feature_index] <= threshold]\n",
    "    right_indices = [i for i in range(len(X)) if X[i][feature_index] > threshold]\n",
    "    return (X[left_indices], y[left_indices]), (X[right_indices], y[right_indices])\n",
    "\n",
    "# Best Split Calculation\n",
    "def best_split(X, y, features):\n",
    "    best_gain = 0\n",
    "    best_feature, best_threshold = None, None\n",
    "    current_gini = gini(y)\n",
    "\n",
    "    for feature_idx in features:\n",
    "        thresholds = np.unique(X[:, feature_idx])\n",
    "        for t in thresholds:\n",
    "            (X_left, y_left), (X_right, y_right) = split_dataset(X, y, feature_idx, t)\n",
    "            \n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "            \n",
    "            gain = current_gini - (\\\n",
    "                (len(y_left)/len(y)) * gini(y_left) +\\\n",
    "                (len(y_right)/len(y)) * gini(y_right)\\\n",
    "            )\n",
    "            \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature_idx\n",
    "                best_threshold = t\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "# Tree Node Class\n",
    "class TreeNode:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value # Class label for leaf node\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "\n",
    "# Build Decision Tree\n",
    "def build_tree(X, y, depth=0, max_depth=10, min_samples=5, num_features=None):\n",
    "    # Stop splitting if conditions are met\n",
    "    if len(set(y)) == 1 or len(y) < min_samples or depth >= max_depth:\n",
    "        # Return leaf node with most common class\n",
    "        return TreeNode(value=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    n_features = X.shape[1]\n",
    "    # Select a subset of features for Random Forest (feature bagging)\n",
    "    features_to_consider = np.random.choice(n_features, num_features or n_features, replace=False)\n",
    "    \n",
    "    best_feat, best_thresh = best_split(X, y, features_to_consider)\n",
    "\n",
    "    # If no split improves Gini impurity, make it a leaf node\n",
    "    if best_feat is None:\n",
    "        return TreeNode(value=Counter(y).most_common(1)[0][0])\n",
    "\n",
    "    (X_left, y_left), (X_right, y_right) = split_dataset(X, y, best_feat, best_thresh)\n",
    "    \n",
    "    # Recursively build left and right sub-trees\n",
    "    left_branch = build_tree(X_left, y_left, depth + 1, max_depth, min_samples, num_features)\n",
    "    right_branch = build_tree(X_right, y_right, depth + 1, max_depth, min_samples, num_features)\n",
    "\n",
    "    return TreeNode(feature=best_feat, threshold=best_thresh, left=left_branch, right=right_branch)\n",
    "\n",
    "# Tree Prediction\n",
    "def predict_tree(x, tree):\n",
    "    if tree.is_leaf():\n",
    "        return tree.value\n",
    "    \n",
    "    # Handle potential None for tree.feature (if prediction on data with less features than training)\n",
    "    if tree.feature is None or tree.feature >= len(x):\n",
    "        # Fallback to majority class of this node if feature is invalid\n",
    "        return tree.value if tree.value is not None else 0 # Or raise error\n",
    "    \n",
    "    if x[tree.feature] <= tree.threshold:\n",
    "        return predict_tree(x, tree.left)\n",
    "    else:\n",
    "        return predict_tree(x, tree.right)\n",
    "\n",
    "# Random Forest Class\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=100, max_depth=10, min_samples=5):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        n_features_sqrt = int(np.sqrt(X.shape[1])) # Features to consider at each split\n",
    "        for _ in range(self.n_trees):\n",
    "            # Bootstrap sampling\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "            \n",
    "            # Build a tree\n",
    "            tree = build_tree(X_sample, y_sample, max_depth=self.max_depth, \n",
    "                              min_samples=self.min_samples, num_features=n_features_sqrt)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Get predictions from all trees\n",
    "        tree_preds = np.array([[predict_tree(x, tree) for tree in self.trees] for x in X])\n",
    "        # Majority vote for final prediction\n",
    "        return [Counter(row).most_common(1)[0][0] for row in tree_preds]\n",
    "\n",
    "print(\"Random Forest implementation loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed616121-90ab-4c3a-9b62-819f93e22a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_rf import RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af2e7c09-92a8-4a43-8a47-f68239dd1744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m forest \u001b[38;5;241m=\u001b[39m RandomForest(n_trees\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m) \u001b[38;5;66;03m# Increased n_trees for better performance\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Random Forest model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m forest\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Make predictions and evaluate\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:90\u001b[0m, in \u001b[0;36mRandomForest.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     88\u001b[0m X_sample, y_sample \u001b[38;5;241m=\u001b[39m X[idx], y[idx]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Train a decision tree on the sample\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m tree \u001b[38;5;241m=\u001b[39m build_tree(X_sample, y_sample, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_depth, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_samples)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:56\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m left_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n\u001b[0;32m     55\u001b[0m right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[1;32m---> 56\u001b[0m left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     57\u001b[0m right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:56\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m left_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n\u001b[0;32m     55\u001b[0m right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[1;32m---> 56\u001b[0m left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     57\u001b[0m right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:57\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     55\u001b[0m         right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[0;32m     56\u001b[0m         left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[1;32m---> 57\u001b[0m         right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# If we reach here, it means we should make a leaf node\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:56\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m left_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n\u001b[0;32m     55\u001b[0m right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[1;32m---> 56\u001b[0m left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     57\u001b[0m right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:57\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     55\u001b[0m         right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[0;32m     56\u001b[0m         left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[1;32m---> 57\u001b[0m         right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# If we reach here, it means we should make a leaf node\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:56\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m left_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n\u001b[0;32m     55\u001b[0m right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[1;32m---> 56\u001b[0m left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     57\u001b[0m right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:56\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m left_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n\u001b[0;32m     55\u001b[0m right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[1;32m---> 56\u001b[0m left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     57\u001b[0m right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n",
      "    \u001b[1;31m[... skipping similar frames: build_tree at line 56 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:56\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     54\u001b[0m left_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m threshold)\n\u001b[0;32m     55\u001b[0m right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[1;32m---> 56\u001b[0m left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     57\u001b[0m right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:57\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     55\u001b[0m         right_mask \u001b[38;5;241m=\u001b[39m (X[:, feature_index] \u001b[38;5;241m>\u001b[39m threshold)\n\u001b[0;32m     56\u001b[0m         left_node \u001b[38;5;241m=\u001b[39m build_tree(X[left_mask], y[left_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[1;32m---> 57\u001b[0m         right_node \u001b[38;5;241m=\u001b[39m build_tree(X[right_mask], y[right_mask], depth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, max_depth, min_samples, num_features)\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# If we reach here, it means we should make a leaf node\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\Forest_Fire_Prediction\\custom_rf.py:60\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(X, y, depth, max_depth, min_samples, num_features)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(feature_index\u001b[38;5;241m=\u001b[39mfeature_index, threshold\u001b[38;5;241m=\u001b[39mthreshold, left\u001b[38;5;241m=\u001b[39mleft_node, right\u001b[38;5;241m=\u001b[39mright_node)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# If we reach here, it means we should make a leaf node\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m leaf_value \u001b[38;5;241m=\u001b[39m Counter(y)\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TreeNode(value\u001b[38;5;241m=\u001b[39mleaf_value)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model Training and Evaluation\n",
    "\n",
    "if X_train_scaled.size > 0:\n",
    "    # Train the Random Forest model\n",
    "    # You can adjust n_trees, max_depth, min_samples\n",
    "    forest = RandomForest(n_trees=100, max_depth=10, min_samples=5) # Increased n_trees for better performance\n",
    "    print(\"Training Random Forest model...\")\n",
    "    forest.fit(X_train_scaled, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Make predictions and evaluate\n",
    "    predictions = forest.predict(X_test_scaled)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"\\nAccuracy of Random Forest (from scratch): {accuracy:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, predictions)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Classification Report\n",
    "    class_report = classification_report(y_test, predictions)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "\n",
    "    # Save the trained model\n",
    "    joblib.dump(forest, 'random_forest_final_model.pkl')\n",
    "    print(\"Random Forest model saved as 'random_forest_final_model.pkl'\")\n",
    "else:\n",
    "    print(\"Skipping model training and evaluation: Training data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db23ed5e-6b59-4674-9750-874bd682256d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler and Random Forest model loaded for manual prediction.\n",
      "\n",
      "--- Interactive Manual Input Prediction ---\n",
      "\n",
      "Enter parameters for prediction:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter latitude:  1\n",
      "Enter longitude:  1\n",
      "Enter temperature:  4\n",
      "Enter humidity:  56\n",
      "Enter wind_speed:  45\n",
      "Enter precipitation:  56\n",
      "Enter elevation:  45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 Prediction for given input: NO FIRE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter latitude:  145\n",
      "Enter longitude:  67\n",
      "Enter temperature:  80\n",
      "Enter humidity:  46\n",
      "Enter wind_speed:  67\n",
      "Enter precipitation:  80\n",
      "Enter elevation:  1467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔥 Prediction for given input: FIRE\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Manual Prediction Function with Automatic VPD Calculation\n",
    "\n",
    "# Ensure calculate_vpd function is available (it's defined in Cell 1 of the full code)\n",
    "# If running this cell independently, you would need to define calculate_vpd here or run Cell 1 first.\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np # Needed for array operations in predict_manual_input\n",
    "# Assuming calculate_vpd is defined from Cell 1\n",
    "\n",
    "# Reload the scaler and model if starting from this cell\n",
    "try:\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    model = joblib.load('random_forest_final_model.pkl')\n",
    "    print(\"Scaler and Random Forest model loaded for manual prediction.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'scaler.pkl' or 'random_forest_final_model.pkl' not found. Please run previous cells to train and save them.\")\n",
    "    scaler = None\n",
    "    model = None\n",
    "\n",
    "if scaler and model:\n",
    "    # Feature names in the order the model expects (after 'acq_date' and 'fire_occurred' removal)\n",
    "    # This order should match the features in df.drop(columns=['fire_occurred', 'acq_date'])\n",
    "    feature_names_for_manual_input = [\n",
    "        'latitude', 'longitude', 'temperature', 'humidity',\n",
    "        'wind_speed', 'precipitation', 'elevation', 'vpd'\n",
    "    ]\n",
    "\n",
    "    def predict_manual_input_interactive():\n",
    "        \"\"\"\n",
    "        Interactively takes manual inputs from the user and makes a fire prediction.\n",
    "        VPD is automatically calculated from temperature and humidity.\n",
    "        \"\"\"\n",
    "        print(\"\\nEnter parameters for prediction:\")\n",
    "        \n",
    "        input_values = {}\n",
    "        # List of features to ask the user for (VPD is calculated, not asked)\n",
    "        features_to_ask = [\n",
    "            'latitude', 'longitude', 'temperature', 'humidity',\n",
    "            'wind_speed', 'precipitation', 'elevation'\n",
    "        ]\n",
    "\n",
    "        for feature in features_to_ask:\n",
    "            while True:\n",
    "                try:\n",
    "                    val = float(input(f\"Enter {feature}: \"))\n",
    "                    input_values[feature] = val\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Please enter a numerical value.\")\n",
    "        \n",
    "        # Automatically calculate VPD\n",
    "        temperature = input_values.get('temperature')\n",
    "        humidity = input_values.get('humidity')\n",
    "        vpd = calculate_vpd(temperature, humidity) # Make sure calculate_vpd is defined (e.g., from Cell 1)\n",
    "        \n",
    "        # Add VPD to the dictionary\n",
    "        input_values['vpd'] = vpd\n",
    "\n",
    "        # Create a DataFrame for a single prediction, ensuring column order matches training data\n",
    "        # Convert the dictionary to a list of values in the correct order\n",
    "        ordered_input = [input_values[feat] for feat in feature_names_for_manual_input]\n",
    "        input_df = pd.DataFrame([ordered_input], columns=feature_names_for_manual_input)\n",
    "\n",
    "        # Convert to numpy array and scale\n",
    "        input_scaled = scaler.transform(input_df.values)\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = model.predict(input_scaled)[0] # [0] because predict returns a list\n",
    "\n",
    "        return \"FIRE\" if prediction == 1 else \"NO FIRE\"\n",
    "\n",
    "    print(\"\\n--- Interactive Manual Input Prediction ---\")\n",
    "    predicted_fire = predict_manual_input_interactive()\n",
    "    print(f\"\\n🔥 Prediction for given input: {predicted_fire}\")\n",
    "\n",
    "else:\n",
    "    print(\"Manual prediction function not available due to missing scaler or model. Please run previous cells to train and save them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c01650-7b9a-448e-a65f-462f44b1616a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Example usage\n",
    "    # Example input data:\n",
    "    # Be careful with the data types and order here.\n",
    "    # Replace with actual values for testing\n",
    "    # example_input = {\n",
    "    #     'latitude': 27.5,\n",
    "    #     'longitude': 85.0,\n",
    "    #     'temperature': 30.0,\n",
    "    #     'humidity': 50.0,\n",
    "    #     'wind_speed': 3.0,\n",
    "    #     'precipitation': 0.1,\n",
    "    #     'elevation': 500.0\n",
    "    # }\n",
    "    # predicted_fire = predict_manual_input(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b07a8f18-6525-4d99-a3d2-b87083201741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.RandomForest'>\n",
      "__main__\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model = joblib.load('random_forest_final_model.pkl')\n",
    "print(type(model))\n",
    "print(model.__class__.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5742b-fc51-40c7-ab2b-d4b328fc1e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
